{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JKBW8grf4dNb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generating result"
      ],
      "metadata": {
        "id": "-Ig5wQ4_3Oip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set model"
      ],
      "metadata": {
        "id": "JKBW8grf4dNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "QR1nlFU-B_LY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "2PcXqYQCCaeO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "A9e_xTkyCrGa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "uvb-2cf5N75-",
        "outputId": "c03e9994-9a72-4241-a83b-fa5465ea1bf7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.0-pro-001')"
      ],
      "metadata": {
        "id": "XybeFXkcEcqH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generate text response/chat response and write it to csv"
      ],
      "metadata": {
        "id": "QxOcZfC44iUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# function"
      ],
      "metadata": {
        "id": "musxHFtOpP70"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5fhvzbpc9vLL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from vertexai.preview.generative_models import (\n",
        "    HarmCategory,\n",
        "    HarmBlockThreshold )\n",
        "from google.cloud.aiplatform_v1beta1.types.content import SafetySetting\n",
        "\n",
        "def getGemini10Pro001Response(prompt):\n",
        "    safety_settings : list[str] = [{\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"}]\n",
        "    response = model.generate_content(prompt,safety_settings = safety_settings).text\n",
        "    return response\n",
        "\n",
        "def getLLMResponse(prompt):\n",
        "    return getGemini10Pro001Response(prompt)\n",
        "\n",
        "def splitQuestion(question):\n",
        "    sentences = question.split('. ')\n",
        "    last_sentence = sentences[-1]\n",
        "    # Remove the last sentence\n",
        "    sentences.pop(-1)\n",
        "    # Join the remaining\n",
        "    new_question = '. '.join(sentences)\n",
        "    return last_sentence, new_question\n",
        "def getGeminiChatResponseNoSub(model,context,question): #model type / large question in str/ subquestions in array\n",
        "    header_instruction = ''' Consider this fictional board game scenario and the rules defined for the scenario: ''' ##### the one for starting the chat\n",
        "    # header_last_instruction=''' Given this, wait for the subproblems I give you and answer them accordingly   '''\n",
        "    final_instruction = ''' Given this, answer the final question: ''' ### what's the best answer etc...\n",
        "    # last_sentence, new_question = splitQuestion(question)\n",
        "    safety_settings : list[str] = [{\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"}]\n",
        "    chat = model.start_chat(history=[])\n",
        "    response = chat.send_message(header_instruction + context + final_instruction + question,\n",
        "                                 safety_settings=safety_settings)\n",
        "    # return response.text\n",
        "    history =\"\"\n",
        "    for message in chat.history:\n",
        "        history += message.role + \": \" + message.parts[0].text + \"\\n\"\n",
        "    return history, response.text\n",
        "\n",
        "def getGeminiChatResponse(model,context,question,subquestions): #model type / large question in str/ subquestions in array\n",
        "    header_instruction = ''' Consider this fictional board game scenario and the rules defined for the scenario: ''' ##### the one for starting the chat\n",
        "    header_last_instruction=''' Given this, wait for the subproblems I give you and answer them accordingly ok?  '''\n",
        "    final_instruction = ''' Given the answers you have generated for the subproblems, answer the final question: ''' ### what's the best answer etc...\n",
        "    # last_sentence, new_question = splitQuestion(question)\n",
        "    safety_settings : list[str] = [{\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"}]\n",
        "    chat = model.start_chat(history=[])\n",
        "    response = chat.send_message(header_instruction + context +header_last_instruction,safety_settings=safety_settings )\n",
        "    for subs in subquestions:\n",
        "        response = chat.send_message(subs,safety_settings=safety_settings)\n",
        "    response  = chat.send_message(final_instruction + question,safety_settings=safety_settings)\n",
        "    # return response.text\n",
        "    history =\"\"\n",
        "    for message in chat.history:\n",
        "        history += message.role + \": \" + message.parts[0].text + \"\\n\"\n",
        "    return history, response.text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "def getBaseAnswers(dataDf):\n",
        "    output_csv_path = '/content/drive/MyDrive/gemini/data/Gemini_results.csv'\n",
        "    #output_csv_path = '/content/drive/MyDrive/gemini/data/Gemini_sub_generation.csv'\n",
        "    with open(output_csv_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Example', 'Response'])\n",
        "        count = 0\n",
        "        for index, row in tqdm(dataDf.iterrows(), total=dataDf.shape[0]):\n",
        "            prompt = row['example'] + \"\\n The label is what (proved, disproved, unknown)?\"\n",
        "            #prompt = \"Based on this question: \"+row['example'] + \"\\n Could you generate some sub-questions?\"+ \"\\n each sub-problem should be divided by '||' \"\n",
        "            response = getLLMResponse(prompt)\n",
        "            writer.writerow([row['example'], response])\n",
        "            count += 1\n",
        "            print(\"The response for \" + str(count) + \"is: \",response)\n",
        "def getSubs(dataDf):\n",
        "    # output_csv_path = '/content/drive/MyDrive/gemini/data/Gemini_results.csv'\n",
        "    output_csv_path = '/content/drive/MyDrive/gemini/data/Gemini_sub_generation.csv'\n",
        "    with open(output_csv_path, mode='a', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # writer.writerow(['Example', 'Response'])\n",
        "        count = 0\n",
        "        for index, row in tqdm(dataDf.iloc[977:].iterrows(), total=dataDf.shape[0]-977):\n",
        "            # prompt = row['example'] + \"\\n The label is what (proved, disproved, unknown)?\"\n",
        "            prompt = \"Based on this question: \"+row['example'] + \"\\n Could you generate some sub-questions?\"+ '''\\n\n",
        "            the response should follow the format: \\n\n",
        "            1: (subquestion1) \\n\n",
        "            2: (subquestion2) \\n\n",
        "            3: (subquestion1) \\n\n",
        "            and so on......'''\n",
        "            response = getLLMResponse(prompt)\n",
        "            writer.writerow([row['example'], response])\n",
        "            count += 1\n",
        "            # print(\"The response for \" + str(count) + \"is: \",response)\n",
        "\n",
        "def getChatResponse(dataDf):\n",
        "    # output_csv_path = '/content/drive/MyDrive/gemini/data/Gemini_final_results.csv'\n",
        "    output_csv_path = '/content/drive/MyDrive/gemini/data/Gemini_decomp_Gemini_sol.csv'\n",
        "    with open(output_csv_path, mode='a', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # writer.writerow(['context','question','answer', 'chat'])\n",
        "        count = 0\n",
        "        for index, row in tqdm(dataDf.iloc[924:].iterrows(), total=dataDf.shape[0]-924):\n",
        "            context = row['context']\n",
        "            question = row['question'] + \"\\n Give me a one word answer (proved, disproved, unknown)\"\n",
        "            subquestion = row[\"parsed_Response\"]\n",
        "            if not subquestion or subquestion == \"nan\":\n",
        "                print(\"no subs\")\n",
        "                history,response = getGeminiChatResponseNoSub(model,context,question)\n",
        "            else:\n",
        "                subquestions = subquestion.split(\"||\")\n",
        "                print(\"have subs\")\n",
        "                history,response = getGeminiChatResponse(model,context,question,subquestions)\n",
        "            writer.writerow([context, question,response,history])\n",
        "            count += 1\n",
        "            # print(\"The response for \" + str(count) + \"is: \",response)\n",
        "def getCOTAnswers(dataDf):\n",
        "    output_csv_path = '/content/drive/MyDrive/gemini/data/Gemini_CoT_results.csv'\n",
        "    CoT = '''\n",
        "        Given the question:\n",
        "            A few players are playing a boardgame. The current state of the game is as follows. The carp rolls the dice for the squirrel. The sea bass sings a victory song for the elephant. And the rules of the game are as follows. Rule1: If the carp rolls the dice for the squirrel, then the squirrel removes from the board one of the pieces of the sheep. Rule2: If the squirrel removes one of the pieces of the sheep and the zander knocks down the fortress of the sheep, then the sheep removes one of the pieces of the whale. Rule3: Regarding the zander, if it took a bike from the store, then we can conclude that it does not knock down the fortress of the sheep. Rule4: The zander knocks down the fortress of the sheep whenever at least one animal sings a song of victory for the elephant. Rule3 is preferred over Rule4. Based on the game state and the rules and preferences, does the sheep remove from the board one of the pieces of the whale?\n",
        "        The reasoning is:\n",
        "            We know the sea bass sings a victory song for the elephant, and according to Rule4 \"if at least one animal sings a victory song for the elephant, then the zander knocks down the fortress of the sheep\", and for the conflicting and higher priority rule Rule3 we cannot prove the antecedent \"the zander took a bike from the store\", so we can conclude \"the zander knocks down the fortress of the sheep\". We know the carp rolls the dice for the squirrel, and according to Rule1 \"if the carp rolls the dice for the squirrel, then the squirrel removes from the board one of the pieces of the sheep\", so we can conclude \"the squirrel removes from the board one of the pieces of the sheep\". We know the squirrel removes from the board one of the pieces of the sheep and the zander knocks down the fortress of the sheep, and according to Rule2 \"if the squirrel removes from the board one of the pieces of the sheep and the zander knocks down the fortress of the sheep, then the sheep removes from the board one of the pieces of the whale\", so we can conclude \"the sheep removes from the board one of the pieces of the whale\". So the statement \"the sheep removes from the board one of the pieces of the whale\" is proved and the answer is \"yes\".\n",
        "        The label is:\n",
        "            proved\n",
        "        Now giving the question: '''\n",
        "    with open(output_csv_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Example', 'Response'])\n",
        "        count = 0\n",
        "        for index, row in tqdm(dataDf.iterrows(), total=dataDf.shape[0]):\n",
        "            prompt = row['example'] + \"\\n The label is what (proved, disproved, unknown)?\"\n",
        "            response = getLLMResponse(prompt)\n",
        "            writer.writerow([row['example'], response])\n",
        "            count += 1\n",
        "            print(\"The response for \" + str(count) + \"is: \",response)"
      ],
      "metadata": {
        "id": "gxOA0Bi0BvGU"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# call"
      ],
      "metadata": {
        "id": "g3T4s_Y6pWBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # dataPath = \"/content/drive/MyDrive/gemini/data/test.json\"\n",
        "    # df = pd.read_json(dataPath, dtype=str)\n",
        "    # getBaseAnswers(df)\n",
        "    #  dataPath = \"/content/drive/MyDrive/gemini/data/output-with-subproblems.json\"\n",
        "    #  df = pd.read_json(dataPath, dtype=str)\n",
        "    #  getChatResponse(df)\n",
        "     dataPath = \"/content/drive/MyDrive/gemini/data/Gemini_parsed_sub_generation.csv\"\n",
        "     df = pd.read_csv(dataPath)\n",
        "     df = df.astype(str)\n",
        "     getChatResponse(df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9AhIDWIzBxO7",
        "outputId": "6d1712b1-6113-4c3a-c177-6413ea90d0c7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/76 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 1/76 [00:16<20:50, 16.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/76 [00:29<17:37, 14.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/76 [00:37<14:00, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 4/76 [00:45<12:09, 10.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/76 [00:55<12:05, 10.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 6/76 [01:02<10:26,  8.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 7/76 [01:21<13:59, 12.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 8/76 [01:34<14:15, 12.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 9/76 [01:45<13:30, 12.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 10/76 [02:03<15:17, 13.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 11/76 [02:21<16:29, 15.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 12/76 [02:40<17:28, 16.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 13/76 [03:00<18:04, 17.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 14/76 [03:13<16:39, 16.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 15/76 [03:32<17:18, 17.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 16/76 [03:45<15:45, 15.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 17/76 [04:01<15:36, 15.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 18/76 [04:23<16:56, 17.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 19/76 [04:47<18:37, 19.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 20/76 [05:05<17:56, 19.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 21/76 [05:22<16:58, 18.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 22/76 [05:44<17:27, 19.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 23/76 [05:52<14:18, 16.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 24/76 [06:11<14:45, 17.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 25/76 [06:22<12:55, 15.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 26/76 [06:42<13:47, 16.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 27/76 [06:43<09:46, 11.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 28/76 [06:58<10:07, 12.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 29/76 [07:12<10:27, 13.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 30/76 [07:32<11:42, 15.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 31/76 [07:53<12:43, 16.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 32/76 [08:01<10:22, 14.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 33/76 [08:17<10:36, 14.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 34/76 [08:32<10:21, 14.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 35/76 [08:52<11:09, 16.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 36/76 [09:17<12:35, 18.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 37/76 [09:34<11:59, 18.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 38/76 [09:50<11:06, 17.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 39/76 [09:51<07:47, 12.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 40/76 [10:15<09:37, 16.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 41/76 [10:26<08:35, 14.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 42/76 [10:44<08:47, 15.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 43/76 [10:51<07:11, 13.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 44/76 [11:10<07:58, 14.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 45/76 [11:30<08:24, 16.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 46/76 [11:44<07:48, 15.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 47/76 [11:58<07:22, 15.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 48/76 [12:06<06:01, 12.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 49/76 [12:23<06:27, 14.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 50/76 [12:34<05:43, 13.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 51/76 [12:46<05:20, 12.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 52/76 [12:54<04:33, 11.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 53/76 [13:06<04:24, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 54/76 [13:25<05:07, 13.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 55/76 [13:33<04:11, 11.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 56/76 [14:04<05:52, 17.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 57/76 [14:15<05:02, 15.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 58/76 [14:35<05:05, 17.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 59/76 [15:43<09:10, 32.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 60/76 [16:05<07:46, 29.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 61/76 [16:27<06:44, 26.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 62/76 [16:57<06:33, 28.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 63/76 [17:07<04:53, 22.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 64/76 [17:27<04:21, 21.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 65/76 [17:45<03:48, 20.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 66/76 [18:10<03:40, 22.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 67/76 [18:12<02:22, 15.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 68/76 [18:53<03:08, 23.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 69/76 [19:22<02:54, 24.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 70/76 [19:32<02:03, 20.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 71/76 [19:43<01:27, 17.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 72/76 [20:00<01:10, 17.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 73/76 [20:13<00:48, 16.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 74/76 [20:24<00:29, 14.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 75/76 [20:40<00:15, 15.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have subs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [20:58<00:00, 16.56s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/gemini/data/Gemini_decomp_Gemini_sol.csv')\n",
        "\n",
        "# The length of the DataFrame is the number of rows excluding the header\n",
        "row_count = len(df)\n",
        "\n",
        "print(f\"Number of rows excluding the header: {row_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POxwZd_abVtT",
        "outputId": "51945afa-9af7-4dc8-a2a6-caa1e2db1f9d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows excluding the header: 924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def CoT():\n",
        "    dataPath = \"/content/drive/MyDrive/gemini/data/test.json\"\n",
        "    with open(dataPath, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "    df = pd.DataFrame(data)\n",
        "    getCOTAnswers(df)\n",
        "CoT()"
      ],
      "metadata": {
        "id": "dLHA9Yi1LAMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Generate_subs():\n",
        "    dataPath = \"/content/drive/MyDrive/gemini/data/test.json\"\n",
        "    with open(dataPath, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "    df = pd.DataFrame(data)\n",
        "    getSubs(df)\n",
        "Generate_subs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "806ZwyB9l60H",
        "outputId": "e12cba69-bf09-49f6-c850-f4a5e4762ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [00:58<00:00,  2.54s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Process Answer"
      ],
      "metadata": {
        "id": "-ZmeUbOk3Vih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Header"
      ],
      "metadata": {
        "id": "1i1SAZNd3j2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### subs"
      ],
      "metadata": {
        "id": "XQiffIt0_qif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "file_path = '/content/drive/MyDrive/gemini/data/Gemini_final_results.csv'\n",
        "\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file)\n",
        "    header = next(reader)\n",
        "    print(f\"Header: {header}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg768M7JsquS",
        "outputId": "daca219f-66b9-4567-db9e-f47f60058fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header: ['context', 'question', 'answer', 'chat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### base"
      ],
      "metadata": {
        "id": "ktPTrzmJ_yUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path2 = '/content/drive/MyDrive/gemini/data/Gemini_results.csv'\n",
        "\n",
        "with open(file_path2, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file)\n",
        "    header = next(reader)\n",
        "    print(f\"Header: {header}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feoce87o9Xap",
        "outputId": "d9eb6e5a-e697-4c74-ead0-62a6ec6286a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header: ['Example', 'Response']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cot"
      ],
      "metadata": {
        "id": "ag09bS1ETatU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "file_path = '/content/drive/MyDrive/gemini/data/Gemini_CoT_results.csv'\n",
        "\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file)\n",
        "    header = next(reader)\n",
        "    print(f\"Header: {header}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74l0hfYcTeM5",
        "outputId": "f3db92de-975a-475e-88d8-4256c593842c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header: ['Example', 'Response']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gene_subs"
      ],
      "metadata": {
        "id": "_ugG9lu2WiNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "file_path = '/content/drive/MyDrive/gemini/data/Gemini_decomp_Gemini_sol.csv'\n",
        "\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file)\n",
        "    header = next(reader)\n",
        "    print(f\"Header: {header}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkfsbSSzWfME",
        "outputId": "1217e021-2b31-4e0b-b230-8f2619238ccf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header: ['context', 'question', 'answer', 'chat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change all answer to lower"
      ],
      "metadata": {
        "id": "NuKeQTGa3pcs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### subs"
      ],
      "metadata": {
        "id": "Gvo19RzO_170"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "file_path = '/content/drive/MyDrive/gemini/data/Gemini_final_results.csv'\n",
        "column_name = 'answer'\n",
        "\n",
        "modified_rows = []\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    headers = reader.fieldnames\n",
        "    for row in reader:\n",
        "        row[column_name] = row[column_name].lower()  # Convert to lowercase\n",
        "        modified_rows.append(row)\n",
        "\n",
        "with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=headers)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(modified_rows)"
      ],
      "metadata": {
        "id": "6rKG_JvIpGwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### base"
      ],
      "metadata": {
        "id": "gbeBbu2N_4Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "file_path = '/content/drive/MyDrive/gemini/data/Gemini_results.csv'\n",
        "column_name = 'Response'\n",
        "\n",
        "modified_rows = []\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    headers = reader.fieldnames\n",
        "    for row in reader:\n",
        "        row[column_name] = row[column_name].lower()  # Convert to lowercase\n",
        "        modified_rows.append(row)\n",
        "\n",
        "with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=headers)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(modified_rows)"
      ],
      "metadata": {
        "id": "9gO5Gkcg9glr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cot"
      ],
      "metadata": {
        "id": "kdHRVPETTk0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "file_path = '/content/drive/MyDrive/gemini/data/Gemini_CoT_results.csv'\n",
        "column_name = 'Response'\n",
        "\n",
        "modified_rows = []\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    headers = reader.fieldnames\n",
        "    for row in reader:\n",
        "        row[column_name] = row[column_name].lower()  # Convert to lowercase\n",
        "        modified_rows.append(row)\n",
        "\n",
        "with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=headers)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(modified_rows)"
      ],
      "metadata": {
        "id": "5roYXBeWTmBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gene_subs"
      ],
      "metadata": {
        "id": "xDB-2T_nWzcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "file_path = '/content/drive/MyDrive/gemini/data/Gemini_decomp_Gemini_sol.csv'\n",
        "column_name = 'answer'\n",
        "\n",
        "modified_rows = []\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    headers = reader.fieldnames\n",
        "    for row in reader:\n",
        "        row[column_name] = row[column_name].lower()  # Convert to lowercase\n",
        "        modified_rows.append(row)\n",
        "\n",
        "with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=headers)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(modified_rows)"
      ],
      "metadata": {
        "id": "jZkFJpbWW2L4"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check the answer and update the csv"
      ],
      "metadata": {
        "id": "0v876JoP315T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### subs"
      ],
      "metadata": {
        "id": "fqn-uAQ-_7i9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "file_path = '/content/drive/MyDrive/gemini/data/Gemini_final_results.csv'\n",
        "column_name = 'answer'\n",
        "def contains_all_three(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    unknown_pattern = r'\\bunknown\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is not None\n",
        "    has_disproved = re.search(disproved_pattern, text) is not None\n",
        "    has_unknown = re.search(unknown_pattern, text) is not None\n",
        "    return has_proved and has_disproved and has_unknown\n",
        "def contains_both_proved_disproved(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is not None\n",
        "    has_disproved = re.search(disproved_pattern, text) is not None\n",
        "    return has_proved and has_disproved\n",
        "def contains_proved(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is not None\n",
        "    return has_proved\n",
        "def contains_disproved(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    has_disproved = re.search(disproved_pattern, text) is not None\n",
        "    return has_disproved\n",
        "def contains_unknown(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    unknown_pattern = r'\\bunknown\\b'\n",
        "    has_unknown = re.search(unknown_pattern, text) is not None\n",
        "    return has_unknown\n",
        "def contains_none(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    unknown_pattern = r'\\bunknown\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is None\n",
        "    has_disproved = re.search(disproved_pattern, text) is None\n",
        "    has_unknown = re.search(unknown_pattern, text) is None\n",
        "    return has_proved and has_disproved and has_unknown\n",
        "modified_rows = []\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    countb = 0\n",
        "    countp = 0\n",
        "    countd = 0\n",
        "    countu = 0\n",
        "    counta = 0\n",
        "    countn = 0\n",
        "    for index, row in enumerate(reader, start=1):\n",
        "        column_value = row[column_name]\n",
        "        if contains_all_three(column_value):\n",
        "            counta +=1\n",
        "        if contains_none(column_value):\n",
        "            print(\"the index for none: \",index)\n",
        "            countn +=1\n",
        "            row[column_name] = \"proved\"\n",
        "        if contains_both_proved_disproved(column_value):\n",
        "            countb +=1\n",
        "        if contains_proved(column_value):\n",
        "            countp +=1\n",
        "            row[column_name] = \"proved\"\n",
        "        if contains_disproved(column_value):\n",
        "            countd +=1\n",
        "            row[column_name] = \"disproved\"\n",
        "        if contains_unknown(column_value):\n",
        "            countu +=1\n",
        "            row[column_name] = \"unknown\"\n",
        "        modified_rows.append(row)\n",
        "    print(\"all three: \",counta)\n",
        "    print(\"none: \",countn)\n",
        "    print(\"both p and d: \",countb)\n",
        "    print(\"proved: \",countp)\n",
        "    print(\"disproved: \",countd)\n",
        "    print(\"unknown: \",countu)\n",
        "    print(\"total: \",len(modified_rows))\n",
        "with open(\"/content/drive/MyDrive/gemini/data/updated_final_results.csv\", mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=reader.fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(modified_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZbDBgLsqDoG",
        "outputId": "dd4b5c65-4633-4b69-aade-db4697447489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the index for none:  153\n",
            "all three:  0\n",
            "none:  1\n",
            "both p and d:  0\n",
            "proved:  286\n",
            "disproved:  411\n",
            "unknown:  302\n",
            "total:  1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### base"
      ],
      "metadata": {
        "id": "ZADO2yFw_-wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "file_path = '/content/drive/MyDrive/gemini/data/Gemini_results.csv'\n",
        "column_name = 'Response'\n",
        "def contains_all_three(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    unknown_pattern = r'\\bunknown\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is not None\n",
        "    has_disproved = re.search(disproved_pattern, text) is not None\n",
        "    has_unknown = re.search(unknown_pattern, text) is not None\n",
        "    return has_proved and has_disproved and has_unknown\n",
        "def contains_both_proved_disproved(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is not None\n",
        "    has_disproved = re.search(disproved_pattern, text) is not None\n",
        "    return has_proved and has_disproved\n",
        "def contains_proved(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is not None\n",
        "    return has_proved\n",
        "def contains_disproved(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    has_disproved = re.search(disproved_pattern, text) is not None\n",
        "    return has_disproved\n",
        "def contains_unknown(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    unknown_pattern = r'\\bunknown\\b'\n",
        "    has_unknown = re.search(unknown_pattern, text) is not None\n",
        "    return has_unknown\n",
        "def contains_none(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    unknown_pattern = r'\\bunknown\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is None\n",
        "    has_disproved = re.search(disproved_pattern, text) is None\n",
        "    has_unknown = re.search(unknown_pattern, text) is None\n",
        "    return has_proved and has_disproved and has_unknown\n",
        "modified_rows = []\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    countb = 0\n",
        "    countp = 0\n",
        "    countd = 0\n",
        "    countu = 0\n",
        "    counta = 0\n",
        "    countn = 0\n",
        "    for index, row in enumerate(reader, start=1):\n",
        "        column_value = row[column_name]\n",
        "        if contains_all_three(column_value):\n",
        "            counta +=1\n",
        "        if contains_none(column_value):\n",
        "            countn +=1\n",
        "        if contains_both_proved_disproved(column_value):\n",
        "            countb +=1\n",
        "        if contains_proved(column_value):\n",
        "            countp +=1\n",
        "            row[column_name] = \"proved\"\n",
        "        if contains_disproved(column_value):\n",
        "            countd +=1\n",
        "            row[column_name] = \"disproved\"\n",
        "        if contains_unknown(column_value):\n",
        "            countu +=1\n",
        "            row[column_name] = \"unknown\"\n",
        "        modified_rows.append(row)\n",
        "    print(\"all three: \",counta)\n",
        "    print(\"none: \",countn)\n",
        "    print(\"both p and d: \",countb)\n",
        "    print(\"proved: \",countp)\n",
        "    print(\"disproved: \",countd)\n",
        "    print(\"unknown: \",countu)\n",
        "    print(\"total: \",len(modified_rows))\n",
        "with open(\"/content/drive/MyDrive/gemini/data/updated_gemini_results.csv\", mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=reader.fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(modified_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUzMS2UZ-BZ4",
        "outputId": "2939652c-9030-4721-a2e3-cbded3c4397f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all three:  0\n",
            "none:  0\n",
            "both p and d:  0\n",
            "proved:  357\n",
            "disproved:  443\n",
            "unknown:  200\n",
            "total:  1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cot"
      ],
      "metadata": {
        "id": "a7bLFdDLTw1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "file_path = '/content/drive/MyDrive/gemini/data/Gemini_CoT_results.csv'\n",
        "column_name = 'Response'\n",
        "def contains_all_three(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    unknown_pattern = r'\\bunknown\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is not None\n",
        "    has_disproved = re.search(disproved_pattern, text) is not None\n",
        "    has_unknown = re.search(unknown_pattern, text) is not None\n",
        "    return has_proved and has_disproved and has_unknown\n",
        "def contains_both_proved_disproved(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is not None\n",
        "    has_disproved = re.search(disproved_pattern, text) is not None\n",
        "    return has_proved and has_disproved\n",
        "def contains_proved(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is not None\n",
        "    return has_proved\n",
        "def contains_disproved(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    has_disproved = re.search(disproved_pattern, text) is not None\n",
        "    return has_disproved\n",
        "def contains_unknown(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    unknown_pattern = r'\\bunknown\\b'\n",
        "    has_unknown = re.search(unknown_pattern, text) is not None\n",
        "    return has_unknown\n",
        "def contains_none(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    unknown_pattern = r'\\bunknown\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is None\n",
        "    has_disproved = re.search(disproved_pattern, text) is None\n",
        "    has_unknown = re.search(unknown_pattern, text) is None\n",
        "    return has_proved and has_disproved and has_unknown\n",
        "modified_rows = []\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    countb = 0\n",
        "    countp = 0\n",
        "    countd = 0\n",
        "    countu = 0\n",
        "    counta = 0\n",
        "    countn = 0\n",
        "    for index, row in enumerate(reader, start=1):\n",
        "        column_value = row[column_name]\n",
        "        if contains_all_three(column_value):\n",
        "            counta +=1\n",
        "        if contains_none(column_value):\n",
        "            countn +=1\n",
        "        if contains_both_proved_disproved(column_value):\n",
        "            countb +=1\n",
        "        if contains_proved(column_value):\n",
        "            countp +=1\n",
        "            row[column_name] = \"proved\"\n",
        "        if contains_disproved(column_value):\n",
        "            countd +=1\n",
        "            row[column_name] = \"disproved\"\n",
        "        if contains_unknown(column_value):\n",
        "            countu +=1\n",
        "            row[column_name] = \"unknown\"\n",
        "        modified_rows.append(row)\n",
        "    print(\"all three: \",counta)\n",
        "    print(\"none: \",countn)\n",
        "    print(\"both p and d: \",countb)\n",
        "    print(\"proved: \",countp)\n",
        "    print(\"disproved: \",countd)\n",
        "    print(\"unknown: \",countu)\n",
        "    print(\"total: \",len(modified_rows))\n",
        "with open(\"/content/drive/MyDrive/gemini/data/Gemini_parsed_CoT_results.csv\", mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=reader.fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(modified_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZGaZJt7Tx7c",
        "outputId": "e7bf6222-2b89-42c8-94e0-475abda90971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all three:  0\n",
            "none:  0\n",
            "both p and d:  0\n",
            "proved:  331\n",
            "disproved:  448\n",
            "unknown:  221\n",
            "total:  1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gene_subs"
      ],
      "metadata": {
        "id": "Z8yAW4SMXEl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "file_path = '/content/drive/MyDrive/gemini/data/Gemini_decomp_Gemini_sol.csv'\n",
        "column_name = 'answer'\n",
        "def contains_all_three(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    unknown_pattern = r'\\bunknown\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is not None\n",
        "    has_disproved = re.search(disproved_pattern, text) is not None\n",
        "    has_unknown = re.search(unknown_pattern, text) is not None\n",
        "    return has_proved and has_disproved and has_unknown\n",
        "def contains_both_proved_disproved(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is not None\n",
        "    has_disproved = re.search(disproved_pattern, text) is not None\n",
        "    return has_proved and has_disproved\n",
        "def contains_proved(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is not None\n",
        "    return has_proved\n",
        "def contains_disproved(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    has_disproved = re.search(disproved_pattern, text) is not None\n",
        "    return has_disproved\n",
        "def contains_unknown(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    unknown_pattern = r'\\bunknown\\b'\n",
        "    has_unknown = re.search(unknown_pattern, text) is not None\n",
        "    return has_unknown\n",
        "def contains_none(text):\n",
        "    # Regular expression pattern to match whole words only\n",
        "    proved_pattern = r'\\bproved\\b'\n",
        "    disproved_pattern = r'\\bdisproved\\b'\n",
        "    unknown_pattern = r'\\bunknown\\b'\n",
        "    has_proved = re.search(proved_pattern, text) is None\n",
        "    has_disproved = re.search(disproved_pattern, text) is None\n",
        "    has_unknown = re.search(unknown_pattern, text) is None\n",
        "    return has_proved and has_disproved and has_unknown\n",
        "modified_rows = []\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    countb = 0\n",
        "    countp = 0\n",
        "    countd = 0\n",
        "    countu = 0\n",
        "    counta = 0\n",
        "    countn = 0\n",
        "    for index, row in enumerate(reader, start=1):\n",
        "        column_value = row[column_name]\n",
        "        if contains_all_three(column_value):\n",
        "            counta +=1\n",
        "        if contains_none(column_value):\n",
        "            countn +=1\n",
        "        if contains_both_proved_disproved(column_value):\n",
        "            countb +=1\n",
        "        if contains_proved(column_value):\n",
        "            countp +=1\n",
        "            row[column_name] = \"proved\"\n",
        "        if contains_disproved(column_value):\n",
        "            countd +=1\n",
        "            row[column_name] = \"disproved\"\n",
        "        if contains_unknown(column_value):\n",
        "            countu +=1\n",
        "            row[column_name] = \"unknown\"\n",
        "        modified_rows.append(row)\n",
        "    print(\"all three: \",counta)\n",
        "    print(\"none: \",countn)\n",
        "    print(\"both p and d: \",countb)\n",
        "    print(\"proved: \",countp)\n",
        "    print(\"disproved: \",countd)\n",
        "    print(\"unknown: \",countu)\n",
        "    print(\"total: \",len(modified_rows))\n",
        "with open(\"/content/drive/MyDrive/gemini/data/Gemini_parsed_decomp_Gemini_sol.csv\", mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=reader.fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(modified_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0hAkOPgXGSY",
        "outputId": "3a4783e4-6674-4767-e071-39c20f1d803b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all three:  0\n",
            "none:  0\n",
            "both p and d:  0\n",
            "proved:  240\n",
            "disproved:  441\n",
            "unknown:  319\n",
            "total:  1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checked the one didn't contain any of the three for subs"
      ],
      "metadata": {
        "id": "1uXjGQ_k3-Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/gemini/data/Gemini_decomp_Gemini_sol.csv'\n",
        "column_name = 'answer'\n",
        "\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for index, row in enumerate(reader):\n",
        "        if index ==432:\n",
        "            print(row[column_name])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHgXeM6PqRaX",
        "outputId": "fcd11622-06b2-4f8c-fccd-2feef503218b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disproved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## change value for index"
      ],
      "metadata": {
        "id": "743MKxyaYWuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/gemini/data/Gemini_decomp_Gemini_sol.csv')\n",
        "df.at[432, 'answer'] = \"disproved\"\n",
        "df.to_csv('/content/drive/MyDrive/gemini/data/Gemini_decomp_Gemini_sol.csv', index=False)"
      ],
      "metadata": {
        "id": "6or-k8Y-YaCc"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recheck the answer for subs"
      ],
      "metadata": {
        "id": "NSRoR6mX4OKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "file_path = '/content/drive/MyDrive/gemini/data/updated_final_results.csv'\n",
        "column_name = 'answer'\n",
        "\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    count = 1\n",
        "    for row in reader:\n",
        "        print(str(count) + \": \" + row[column_name])\n",
        "        count +=1"
      ],
      "metadata": {
        "id": "nBmwGgmGnBVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy check"
      ],
      "metadata": {
        "id": "QPW8Lnk244kn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using subs"
      ],
      "metadata": {
        "id": "8IgC629G8xkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataPath = \"/content/drive/MyDrive/gemini/data/output-with-subproblems.json\"\n",
        "dataDf = pd.read_json(dataPath, dtype=str)\n",
        "file_path = '/content/drive/MyDrive/gemini/data/updated_final_results.csv'\n",
        "column_name = 'answer'\n",
        "label = []\n",
        "predicted = []\n",
        "for index, row in tqdm(dataDf.iterrows(), total=dataDf.shape[0]):\n",
        "    label.append(row['label'])\n",
        "with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        predicted.append(row[column_name])\n",
        "print(len(predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsieTSvu4zwI",
        "outputId": "41c718a0-58b6-4fdb-f750-163001312e55"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 10773.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(label) == len(predicted):\n",
        "    matches = sum(1 for label_value, predicted_value in zip(label, predicted) if label_value == predicted_value)\n",
        "    accuracy = matches / len(label)\n",
        "    print(f\"Accuracy using subproblems: {accuracy:.2%}\")\n",
        "else:\n",
        "    print(\"Error: The lists 'label' and 'predicted' have different lengths.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAael6j17_ML",
        "outputId": "117db110-abb4-4965-a91b-f672bcf8f0ac"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using subproblems: 51.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The base answer"
      ],
      "metadata": {
        "id": "cn0pHO2Z80tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path2 = '/content/drive/MyDrive/gemini/data/updated_gemini_results.csv'\n",
        "column_name = 'Response'\n",
        "predicted2 = []\n",
        "with open(file_path2, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        predicted2.append(row[column_name])\n",
        "print(len(predicted2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYKqOGNP8649",
        "outputId": "7aea41b6-b636-4ddb-ce92-4e35492fe66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(label) == len(predicted2):\n",
        "    matches = sum(1 for label_value, predicted_value in zip(label, predicted2) if label_value == predicted_value)\n",
        "    accuracy = matches / len(label)\n",
        "    print(f\"Accuracy without using subproblems: {accuracy:.2%}\")\n",
        "else:\n",
        "    print(\"Error: The lists 'label' and 'predicted' have different lengths.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8TtBT1r_ItR",
        "outputId": "6d302482-3144-495b-f099-59bb69458fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without using subproblems: 45.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The CoT answer"
      ],
      "metadata": {
        "id": "K6I8xf_LUX1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path3 = '/content/drive/MyDrive/gemini/data/Gemini_parsed_CoT_results.csv'\n",
        "column_name = 'Response'\n",
        "predicted3 = []\n",
        "with open(file_path3, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        predicted3.append(row[column_name])\n",
        "print(len(predicted3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b2ad59-0273-4f9e-9d6e-49d939095cec",
        "id": "s8YPbIK6UX1d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(label) == len(predicted3):\n",
        "    matches = sum(1 for label_value, predicted_value in zip(label, predicted3) if label_value == predicted_value)\n",
        "    accuracy = matches / len(label)\n",
        "    print(f\"Accuracy using CoT: {accuracy:.2%}\")\n",
        "else:\n",
        "    print(\"Error: The lists 'label' and 'predicted' have different lengths.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be48cff0-ae98-482b-9195-ed9b76655eb7",
        "id": "s_TcYJl9UX1d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using CoT: 42.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gemini-decomp-gemini-solver"
      ],
      "metadata": {
        "id": "rnIhPe_wZN8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path3 = '/content/drive/MyDrive/gemini/data/Gemini_parsed_decomp_Gemini_sol.csv'\n",
        "column_name = 'answer'\n",
        "predicted3 = []\n",
        "with open(file_path3, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        predicted3.append(row[column_name])\n",
        "print(len(predicted3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQUBe4XkZTf-",
        "outputId": "d8f255bb-f641-44ed-a92e-a61fb18edf15"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(label) == len(predicted3):\n",
        "    matches = sum(1 for label_value, predicted_value in zip(label, predicted3) if label_value == predicted_value)\n",
        "    accuracy = matches / len(label)\n",
        "    print(f\"Accuracy using gemini-decomp-gemini-solver: {accuracy:.2%}\")\n",
        "else:\n",
        "    print(\"Error: The lists 'label' and 'predicted' have different lengths.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LERl4kxjZWHy",
        "outputId": "377cfa79-a752-4e8a-ebdf-037f5304c7de"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using gemini-decomp-gemini-solver: 50.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# parse answer"
      ],
      "metadata": {
        "id": "bqF_QpKs0uTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/gemini/data/Gemini_sub_generation.csv')  # Replace with the actual path to your CSV file\n",
        "\n",
        "#separates the questions with '||'\n",
        "def separate_questions(text):\n",
        "    questions_with_numbers = re.findall(r'(\\d+: .*?\\?)', text)\n",
        "    return ' || '.join(questions_with_numbers)\n",
        "\n",
        "df['parsed_Response'] = df['Response'].apply(separate_questions)\n",
        "df.to_csv('/content/drive/MyDrive/gemini/data/Gemini_parsed_sub_generation.csv', index=False)  # Replace with your desired output file path"
      ],
      "metadata": {
        "id": "ttoXJ1Wy0wU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load and prepare the JSON data\n",
        "with open('/content/drive/MyDrive/gemini/data/output-with-subproblems.json', 'r') as file:\n",
        "    json_data = json.load(file)\n",
        "columns_needed = ['context', 'question']\n",
        "new_columns_df = pd.DataFrame(json_data)[columns_needed]\n",
        "\n",
        "# Load the original CSV\n",
        "original_df = pd.read_csv('/content/drive/MyDrive/gemini/data/Gemini_parsed_sub_generation.csv')\n",
        "\n",
        "# Concatenate and save\n",
        "updated_df = pd.concat([original_df, new_columns_df], axis=1)\n",
        "updated_df.to_csv('/content/drive/MyDrive/gemini/data/Gemini_parsed_sub_generation.csv', index=False)"
      ],
      "metadata": {
        "id": "ZnylRyy63DpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pa = '/content/drive/MyDrive/gemini/data/Gemini_parsed_sub_generation.csv'\n",
        "# Load the CSV into a DataFrame\n",
        "df = pd.read_csv(pa)\n",
        "\n",
        "# Delete the \"Example\" column\n",
        "df = df.drop('Example', axis=1)\n",
        "\n",
        "# Save the modified DataFrame back to the CSV\n",
        "df.to_csv(pa, index=False)"
      ],
      "metadata": {
        "id": "W15Dr5vi4tzw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}